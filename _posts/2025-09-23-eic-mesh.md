---
title: GaTech EIC Mesh project
description: 解题过程
author: cybotiger
date: 2025-09-23 12:00:00 +0800
categories: [AI, Vision]
tags: []
math: true
mermaid: true
---

## step 1
Find a depth estimation model that takes the RGB image as the input and
outputs the corresponding depth. Here, let’s use DistDepth, which can provide the
absolute depth from the origin of the cameras to the surface of the objects in the
scene.

## step 2
Merge the depth estimation results from multiple images into one point
cloud. Please refer to [this script](https://github.com/facebookresearch/DistDepth/blob/main/visualize_pc.py) to learn how to convert the depth estimation to the
point cloud based on the intrinsic and extrinsic of the camera.

![alt text](assets/img/eic-mesh/image.png)

![alt text](assets/img/eic-mesh/image1.png)

发现问题来源：DistDepth 模型是在 SimSIN 合成环境中进行训练的，训练时采用 1.312 的 scale

突然发现 color image 在经过 resize 和 crop 后，intrinsic 矩阵也需要经过相应的调整，调整过后稍微好了一些，但是还是很差s

## step 3
Convert the point cloud into mesh by first converting the point cloud into a
3D grid (you can define the resolution of the 3D grid yourself, but we recommend
256 * 256 * 256), where each item in the 3D grid represents the normalized number
of points (normalized to the max value of all items), which is in the range of [0, 1].
Then, we convert such a 3D grid into mesh via a [marching cube](https://scikit-image.org/docs/stable/api/skimage.measure.html#skimage.measure.marching_cubes). The marching
cube implementation is described in [this script](https://github.com/apchenstu/TensoRF/blob/17deeedae5ab4106b30a3295709ec3a8a654c7b1/utils.py#L161).

## step 4
Fine-tune the mesh’s vertices positions and colors using [nvdiffrec](https://github.com/NVlabs/nvdiffrec/tree/main) with the
RGB images as training data. To simplify the fine-tuning process, please just learn
the RGB color and position for each vertex instead of the combination of PBR
materials and environment light in the official codebase of [nvdiffrec](https://github.com/NVlabs/nvdiffrec/tree/main).